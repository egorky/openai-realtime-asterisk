# UNIQUE_CHANGE_MARKER_FOR_SUBTASK_XYZ_123
# rename this to .env

# OpenAI Configuration
OPENAI_API_KEY="sk-your_openai_api_key_here" # Your OpenAI API Key - REQUIRED
OPENAI_REALTIME_MODEL="gpt-4o-mini-realtime-preview-2024-12-17" # OpenAI Realtime model ID (e.g., gpt-4o-realtime-..., gpt-4o-mini-realtime-...) - REQUIRED
# Instructions are now loaded from the agent configuration selected by ACTIVE_AGENT_CONFIG_KEY
# OPENAI_INSTRUCTIONS="Eres un asistente de IA amigable y servicial. Responde de manera concisa." # Default system instructions for the OpenAI model.
ACTIVE_AGENT_CONFIG_KEY="chatSupervisor" # Key for the agent configuration to load from config/agentConfigs/index.ts (e.g., "simpleHandoff", "customerServiceRetail", "chatSupervisor")
OPENAI_RESPONSE_MODALITIES="audio,text" # Desired response types from OpenAI: comma-separated list from "audio", "text" (e.g., "audio,text" or "text")
OPENAI_TTS_MODEL="tts-1" # OpenAI TTS model (e.g., tts-1, tts-1-hd) - Used if Realtime API doesn't handle TTS or for separate TTS calls.
OPENAI_TTS_VOICE="alloy" # OpenAI TTS voice (e.g., alloy, echo, fable, onyx, nova, shimmer) - Used for TTS.
OPENAI_LANGUAGE="en" # Language code for STT (e.g., en, es). For Realtime API, language support is often model-specific.
OPENAI_INPUT_AUDIO_FORMAT="g711_ulaw" # Format of input audio sent to OpenAI. For direct u-law (8kHz) passthrough from Asterisk, set to "g711_ulaw" or the exact equivalent string OpenAI expects. VERIFY WITH OPENAI DOCS.
OPENAI_INPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for STT input. Note: For Realtime API with formats like "g711_ulaw", the sample rate (8000) is often implied by the format string. This variable might be used for other internal logic if any, but the format string sent to OpenAI is primary.
OPENAI_OUTPUT_AUDIO_FORMAT="g711_ulaw" # Desired TTS audio output format from OpenAI. For direct u-law (8kHz) playback in Asterisk, "g711_ulaw" or equivalent is recommended. VERIFY WITH OPENAI DOCS.
OPENAI_OUTPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for TTS output. Note: For Realtime API with formats like "g711_ulaw", the sample rate (8000) is often implied by the format string.

# Asterisk ARI Configuration (examples from ari-client.ts defaults)
ASTERISK_ARI_URL="http://localhost:8088"
ASTERISK_ARI_USERNAME="asterisk"
ASTERISK_ARI_PASSWORD="asterisk"
ASTERISK_ARI_APP_NAME="openai-ari-app" # Should match the Stasis app name in Asterisk dialplan
# ASTERISK_INBOUND_CONTEXT: Dialplan context where inbound calls are routed to the ARI application.
ASTERISK_INBOUND_CONTEXT="from-external" # Example context
# ASTERISK_DIAL_EXTENSION: The extension number within ASTERISK_INBOUND_CONTEXT that invokes the ARI app.
ASTERISK_DIAL_EXTENSION="1234" # Example extension

# RTP Host IP (IP address of this server where Asterisk should send RTP media)
RTP_HOST_IP="127.0.0.1" # Use actual host IP if Asterisk is on a different machine or in Docker
# RTP_MIN_PORT: Minimum port for RTP listeners. Default: 10000
RTP_MIN_PORT=10000
# RTP_MAX_PORT: Maximum port for RTP listeners. Default: 10010
RTP_MAX_PORT=10010

# Server Configuration
PORT="8081" # Port for the WebSocket server to listen on
# PUBLIC_URL: The publicly accessible URL for this websocket-server.
PUBLIC_URL="http://localhost:8081"
WEBSOCKET_SERVER_HOST_IP="0.0.0.0" # Host IP for the WebSocket server

# Logging Configuration
LOG_LEVEL="info" # Log level for the application (e.g., "error", "warn", "info", "debug", "silly"). Set to "debug" for verbose OpenAI API message logging.

# Application Behavior Configuration
# RECOGNITION_ACTIVATION_MODE: How recognition is activated. "vad", "manual", "immediate", "fixedDelay". Default: "vad"
RECOGNITION_ACTIVATION_MODE="vad"

# VAD (Voice Activity Detection) Configuration (used when RECOGNITION_ACTIVATION_MODE="vad")
# APP_APPRECOGNITION_VADSILENCETHRESHOLDMS: Asterisk TALK_DETECT silence threshold in ms. Time of silence after speech to trigger ChannelTalkingFinished. Default: 2500
APP_APPRECOGNITION_VADSILENCETHRESHOLDMS=2500
# APP_APPRECOGNITION_VADTALKTHRESHOLD: Asterisk TALK_DETECT energy level threshold above which audio is considered speech, triggering ChannelTalkingStarted. Default: 256
APP_APPRECOGNITION_VADTALKTHRESHOLD=256
# APP_APPRECOGNITION_VADRECOGACTIVATION: For VAD mode: "vadMode" or "afterPrompt". Default: "vadMode"
APP_APPRECOGNITION_VADRECOGACTIVATION="vadMode"
# APP_APPRECOGNITION_VADMAXWAITAFTERPROMPTSECONDS: For VAD mode: Max time (seconds) to wait for speech after prompt finishes (and after vadInitialSilenceDelaySeconds if in "vadMode"). Default: 10.0
APP_APPRECOGNITION_VADMAXWAITAFTERPROMPTSECONDS=10.0
# APP_APPRECOGNITION_VADINITIALSILENCEDELAYSECONDS: For VAD mode with vadRecogActivation="vadMode": Delay (seconds) from call start before VAD actively listens. Audio is buffered. Default: 0.0
APP_APPRECOGNITION_VADINITIALSILENCEDELAYSECONDS=0.0

# Speech Recognition Timers (seconds) - Apply to fixedDelay, Immediate, and VAD modes once OpenAI stream is active
# NO_SPEECH_BEGIN_TIMEOUT_SECONDS: Max time application waits for OpenAI initial activity or an interim transcript. Default: 5.0
NO_SPEECH_BEGIN_TIMEOUT_SECONDS=5.0
# SPEECH_END_SILENCE_TIMEOUT_SECONDS: Max time application waits for a final transcript from OpenAI after each turn. Default: 1.5
SPEECH_END_SILENCE_TIMEOUT_SECONDS=1.5
# MAX_RECOGNITION_DURATION_SECONDS: Absolute maximum duration (seconds) for the entire speech recognition attempt for a single call turn. Default: 30.0
MAX_RECOGNITION_DURATION_SECONDS=30.0
# INITIAL_OPENAI_STREAM_IDLE_TIMEOUT_SECONDS: (Optional) Timeout in seconds for the initial OpenAI stream to become responsive (e.g. send first event). Default: 10
INITIAL_OPENAI_STREAM_IDLE_TIMEOUT_SECONDS=10 # This is largely superseded by NO_SPEECH_BEGIN_TIMEOUT_SECONDS for practical purposes but kept for deeper diagnostics.

# DTMF Configuration
# DTMF_ENABLED: Enable ("true") or disable ("false") DTMF recognition. Default: "true"
DTMF_ENABLED="true"
# DTMF_INTERDIGIT_TIMEOUT_SECONDS: Timeout in seconds between DTMF digits. Default: 3.0
DTMF_INTERDIGIT_TIMEOUT_SECONDS=3.0
# DTMF_FINAL_TIMEOUT_SECONDS: Timeout in seconds after the last DTMF digit to finalize input. Default: 5.0
DTMF_FINAL_TIMEOUT_SECONDS=5.0
# Note: DTMF_MAX_DIGITS and DTMF_TERMINATOR_DIGIT are configured in default.json and not typically overridden by .env

# Barge-In Configuration (Only BARGE_IN_DELAY_SECONDS is actively used by fixedDelay mode)
# BARGE_IN_DELAY_SECONDS: Delay (seconds) before activating recognition in "fixedDelay" mode. Allows caller to speak after prompt starts. Default: 0.2
BARGE_IN_DELAY_SECONDS=0.2
# BARGE_IN_MODE_ENABLED: (Legacy, largely informational as barge-in is implicit in modes). Default: "true"
BARGE_IN_MODE_ENABLED="true"


# Redis Configuration (Optional - for conversation logging)
# REDIS_HOST: Hostname/IP of the Redis server. Default: "127.0.0.1"
# REDIS_HOST="127.0.0.1"
# REDIS_PORT: Port of the Redis server. Default: 6379
# REDIS_PORT=6379
# REDIS_PASSWORD: Password for Redis server (if any). Default: undefined
# REDIS_PASSWORD=
# REDIS_CONVERSATION_TTL_SECONDS: Time-to-live in seconds for conversation logs in Redis. Default: 3600 (1 hour)
# REDIS_CONVERSATION_TTL_SECONDS=3600

# Configuration File Path
# CONFIG_FILE_PATH: Path to the JSON configuration file. Default: "config/default.json"
CONFIG_FILE_PATH="config/default.json"

# Greeting Audio Path (Example - used by ari-client.ts)
# GREETING_AUDIO_PATH="sound:your-custom-greeting" # Path to greeting audio file recognizable by Asterisk

# Async STT Configuration
# ASYNC_STT_ENABLED="false" # Enable ("true") or disable ("false") async STT. Default: "false"
# ASYNC_STT_PROVIDER="openai_whisper_api" # Provider: "openai_whisper_api" or "google_speech_v1". Default: "openai_whisper_api"
# ASYNC_STT_OPENAI_MODEL="whisper-1" # Model for OpenAI Whisper. Default: "whisper-1"
# ASYNC_STT_OPENAI_API_KEY="" # OpenAI API Key for Async STT. Defaults to OPENAI_API_KEY if empty.
# ASYNC_STT_LANGUAGE="en" # Optional language hint for OpenAI Whisper (e.g., "en", "es"). Default: "en"
# ASYNC_STT_AUDIO_FORMAT="mulaw" # Internal audio format passed to async transcriber. Default: "mulaw"
# ASYNC_STT_AUDIO_SAMPLE_RATE="8000" # Sample rate for async STT. Default: 8000
# ASYNC_STT_GOOGLE_LANGUAGE_CODE="es-ES" # Language code for Google Speech (e.g., "en-US", "es-ES"). Default: "es-ES"
# ASYNC_STT_GOOGLE_CREDENTIALS="" # Optional: Path to Google Cloud credentials JSON file. If not set, Application Default Credentials (ADC) will be used.

# Initial Message Configuration
# INITIAL_USER_PROMPT="Hola" # Optional: A synthetic first user message to make the assistant speak first. e.g., "Hola" or "Comenzar la conversaci√≥n."
