# UNIQUE_CHANGE_MARKER_FOR_SUBTASK_XYZ_123
# rename this to .env

################################################################################
# AI Provider Configuration
################################################################################
AI_PROVIDER="openai" # "openai" or "azure"

################################################################################
# OpenAI Configuration (used if AI_PROVIDER="openai")
################################################################################
OPENAI_API_KEY="sk-your_openai_api_key_here" # REQUIRED: Your OpenAI API Key.
OPENAI_REALTIME_MODEL="gpt-4o-mini-realtime-preview-2024-12-17" # REQUIRED: OpenAI Realtime model ID (e.g., gpt-4o-realtime-..., gpt-4o-mini-realtime-...).

################################################################################
# Azure OpenAI Configuration (used if AI_PROVIDER="azure")
################################################################################
AZURE_OPENAI_API_KEY="" # REQUIRED: Your Azure OpenAI API Key.
AZURE_OPENAI_ENDPOINT="" # REQUIRED: Your Azure OpenAI endpoint (e.g., https://your-resource.openai.azure.com/).
AZURE_OPENAI_DEPLOYMENT_ID="" # REQUIRED: Your Azure OpenAI deployment ID.
AZURE_OPENAI_API_VERSION="" # REQUIRED: Your Azure OpenAI API version (e.g., 2024-05-01-preview).

################################################################################
# General Agent & Scenario Configuration
################################################################################
ACTIVE_AGENT_CONFIG_KEY="chatSupervisor" # Specifies which agent configuration (scenario) to load from `config/agentConfigs/index.ts`. Determines assistant's instructions, tools, etc. Example: "customerServiceRetail". Defaults to "chatSupervisor".
# OPENAI_INSTRUCTIONS: This is now dynamically loaded from the agent configuration specified by ACTIVE_AGENT_CONFIG_KEY.
OPENAI_RESPONSE_MODALITIES="audio,text" # Desired response types from OpenAI. Comma-separated list from "audio", "text" (e.g., "audio,text" or "text"). Defaults to "audio,text".
OPENAI_TTS_MODEL="tts-1" # OpenAI TTS model (e.g., tts-1, tts-1-hd). Used if Realtime API doesn't handle TTS as part of the session or for separate/fallback TTS.
OPENAI_TTS_VOICE="alloy" # OpenAI TTS voice (e.g., alloy, echo, fable, onyx, nova, shimmer).
OPENAI_LANGUAGE="en" # Language code for STT (e.g., en, es). For Realtime API, language support is often model-specific or set via instructions.
OPENAI_INPUT_AUDIO_FORMAT="g711_ulaw" # Format of input audio sent to OpenAI. For direct u-law (8kHz) passthrough from Asterisk, set to "g711_ulaw". VERIFY WITH OPENAI DOCS.
OPENAI_INPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for STT input (e.g., 8000, 16000). For "g711_ulaw", 8000 is implied.
OPENAI_OUTPUT_AUDIO_FORMAT="g711_ulaw" # Desired TTS audio output format from OpenAI. For direct u-law (8kHz) playback in Asterisk, "g711_ulaw" is recommended. VERIFY WITH OPENAI DOCS.
OPENAI_OUTPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for TTS output (e.g., 8000, 24000). For "g711_ulaw", 8000 is implied.

################################################################################
# Asterisk ARI Configuration
################################################################################
ASTERISK_ARI_URL="http://localhost:8088" # URL for the Asterisk ARI interface.
ASTERISK_ARI_USERNAME="asterisk" # Username for ARI.
ASTERISK_ARI_PASSWORD="asterisk" # Password for ARI.
ASTERISK_ARI_APP_NAME="openai-ari-app" # The name of your Stasis application in Asterisk (must match dialplan).
# ASTERISK_INBOUND_CONTEXT="from-external" # Example: Dialplan context where inbound calls are routed to this ARI application.
# ASTERISK_DIAL_EXTENSION="1234" # Example: The extension number within ASTERISK_INBOUND_CONTEXT that invokes this ARI app.

################################################################################
# RTP (Media) Server Configuration
################################################################################
RTP_HOST_IP="127.0.0.1" # IP address of this server where Asterisk should send RTP media. Use actual host IP if Asterisk is on a different machine or in Docker.
RTP_MIN_PORT="10000" # Minimum port for RTP listeners. Default: 10000.
RTP_MAX_PORT="10010" # Maximum port for RTP listeners. Default: 10010.

################################################################################
# WebSocket Server Configuration
################################################################################
PORT="8081" # Port for this WebSocket server to listen on.
# PUBLIC_URL="http://localhost:8081" # Optional: The publicly accessible URL for this websocket-server.
WEBSOCKET_SERVER_HOST_IP="0.0.0.0" # Host IP for this WebSocket server to bind to (e.g., 0.0.0.0 for all interfaces).

################################################################################
# Logging Configuration
################################################################################
LOG_LEVEL="info" # Log level for the application (e.g., "error", "warn", "info", "debug", "silly"). "debug" or "silly" enables verbose OpenAI API message logging.

################################################################################
# Application Behavior & Recognition Modes
################################################################################
RECOGNITION_ACTIVATION_MODE="vad" # How recognition is activated. Options: "vad", "Immediate", "fixedDelay". Default: "vad".
# FIRST_INTERACTION_RECOGNITION_MODE="" # Optional. Overrides RECOGNITION_ACTIVATION_MODE for the first interaction only. Same options as above. If empty, uses global mode.
# OPENAI_TTS_PLAYBACK_MODE="full_chunk" # How TTS audio is played. "full_chunk" (wait for all audio) or "stream" (play chunks as they arrive). Default: "full_chunk".

# --- VAD (Voice Activity Detection) Configuration --- (Used when RECOGNITION_ACTIVATION_MODE or FIRST_INTERACTION_RECOGNITION_MODE is "vad")
APP_APPRECOGNITION_VADSILENCETHRESHOLDMS="2500" # Asterisk TALK_DETECT: Time of silence (ms) after speech to trigger ChannelTalkingFinished. Default: 2500.
APP_APPRECOGNITION_VADTALKTHRESHOLD="256" # Asterisk TALK_DETECT: Energy level threshold above which audio is considered speech, triggering ChannelTalkingStarted. Default: 256.
APP_APPRECOGNITION_VADRECOGACTIVATION="vadMode" # For VAD mode: "vadMode" (listen after initial delay) or "afterPrompt" (listen after prompt). Default: "vadMode".
APP_APPRECOGNITION_VADMAXWAITAFTERPROMPTSECONDS="10.0" # For VAD mode: Max time (seconds) to wait for speech after prompt finishes (and after vadInitialSilenceDelaySeconds if in "vadMode"). Default: 10.0.
APP_APPRECOGNITION_VADINITIALSILENCEDELAYSECONDS="0.0" # For VAD mode with vadRecogActivation="vadMode": Delay (seconds) from call start/turn start before VAD actively listens for TALK_DETECT events. Audio is buffered. Default: 0.0.
# VAD_TALK_DURATION_THRESHOLD_MS="40" # Duration (ms) of speech for Asterisk TALK_DETECT's vadRecognitionActivationMs internal config. Default: 40.

# --- Speech Recognition Timers (seconds) --- (Apply to "fixedDelay", "Immediate", and "vad" modes once OpenAI stream is active)
NO_SPEECH_BEGIN_TIMEOUT_SECONDS="5.0" # Max time application waits for OpenAI initial activity (e.g., speech_started or first interim transcript). Default: 5.0.
SPEECH_END_SILENCE_TIMEOUT_SECONDS="1.5" # Max time application waits for a final transcript from OpenAI after the last interim transcript or speech activity. Default: 1.5.
MAX_RECOGNITION_DURATION_SECONDS="30.0" # Absolute maximum duration (seconds) for the entire speech recognition attempt for a single call turn. Default: 30.0.
INITIAL_OPENAI_STREAM_IDLE_TIMEOUT_SECONDS="10" # (Advanced) Timeout in seconds for the initial OpenAI stream to become responsive (send first event). Largely superseded by NO_SPEECH_BEGIN_TIMEOUT_SECONDS. Default: 10.

# --- DTMF Configuration ---
DTMF_ENABLED="true" # Enable ("true") or disable ("false") DTMF recognition. Default: "true".
DTMF_INTERDIGIT_TIMEOUT_SECONDS="3.0" # Timeout in seconds between DTMF digits. Default: 3.0.
DTMF_FINAL_TIMEOUT_SECONDS="5.0" # Overall timeout in seconds after the last DTMF digit to finalize input. Default: 5.0.
# Note: DTMF_MAX_DIGITS and DTMF_TERMINATOR_DIGIT are configured in config/default.json (currently 16 and "#") and not typically overridden by .env.

# --- Barge-In Configuration (fixedDelay mode) ---
BARGE_IN_DELAY_SECONDS="0.2" # Delay (seconds) before activating recognition in "fixedDelay" mode. Allows caller to speak after prompt starts. Default: 0.2.
# BARGE_IN_MODE_ENABLED="true" # (Legacy, largely informational as barge-in is implicit in modes). Default: "true".

################################################################################
# Redis Configuration (Optional - for conversation logging)
################################################################################
# REDIS_HOST="127.0.0.1" # Hostname/IP of the Redis server. Default: "127.0.0.1".
# REDIS_PORT="6379" # Port of the Redis server. Default: 6379.
# REDIS_PASSWORD="" # Password for Redis server (if any). Default: undefined.
# REDIS_CONVERSATION_TTL_SECONDS="3600" # Time-to-live in seconds for conversation logs in Redis. Default: 3600 (1 hour).

################################################################################
# Miscellaneous Configuration
################################################################################
CONFIG_FILE_PATH="config/default.json" # Path to the JSON configuration file. Default: "config/default.json".
# GREETING_AUDIO_PATH="sound:your-custom-greeting" # Path to greeting audio file recognizable by Asterisk (e.g., "sound:hello-world"). Overrides default.json.
# INITIAL_GREETING_AUDIO_PATH="" # Overrides GREETING_AUDIO_PATH and default.json if set.
INITIAL_USER_PROMPT="" # Optional: A synthetic first user message to make the assistant speak first. e.g., "Hola" or "Comenzar la conversaci√≥n."

################################################################################
# Asynchronous STT Configuration (Fallback STT)
################################################################################
ASYNC_STT_ENABLED="false" # Enable ("true") or disable ("false") async STT. Default: "false".
ASYNC_STT_PROVIDER="openai_whisper_api" # Provider: "openai_whisper_api", "google_speech_v1", or "vosk". Default: "openai_whisper_api".
# --- OpenAI Whisper API (for Async STT) ---
ASYNC_STT_OPENAI_MODEL="whisper-1" # Model for OpenAI Whisper. Default: "whisper-1".
ASYNC_STT_OPENAI_API_KEY="" # OpenAI API Key for Async STT. Defaults to main OPENAI_API_KEY if empty.
ASYNC_STT_LANGUAGE="en" # Optional language hint for OpenAI Whisper (e.g., "en", "es"). Default: "en".
# --- Google Cloud Speech-to-Text V1 (for Async STT) ---
# ASYNC_STT_GOOGLE_LANGUAGE_CODE="es-ES" # Language code for Google Speech (e.g., "en-US", "es-ES"). Default: "es-ES".
# ASYNC_STT_GOOGLE_CREDENTIALS="" # Optional: Path to Google Cloud credentials JSON file. If not set, Application Default Credentials (ADC) will be used.
# --- Vosk Offline STT (for Async STT) ---
# VOSK_SERVER_URL="ws://localhost:2700" # WebSocket URL for the Vosk server instance.
# --- Common Async STT Audio Settings ---
ASYNC_STT_AUDIO_FORMAT="mulaw" # Internal audio format passed to async transcriber from buffer. Typically "mulaw" or "wav" (if converted). Default: "mulaw".
ASYNC_STT_AUDIO_SAMPLE_RATE="8000" # Sample rate of the audio buffer for async STT. Default: 8000.
