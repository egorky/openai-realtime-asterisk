# UNIQUE_CHANGE_MARKER_FOR_SUBTASK_XYZ_123
# rename this to .env

# OpenAI Configuration
OPENAI_API_KEY="sk-your_openai_api_key_here" # Your OpenAI API Key - REQUIRED
OPENAI_REALTIME_MODEL="gpt-4o-mini-realtime-preview-2024-12-17" # OpenAI Realtime model ID (e.g., gpt-4o-realtime-..., gpt-4o-mini-realtime-...) - REQUIRED
OPENAI_INSTRUCTIONS="Eres un asistente de IA amigable y servicial. Responde de manera concisa." # Default system instructions for the OpenAI model.
OPENAI_RESPONSE_MODALITIES="audio,text" # Desired response types from OpenAI: comma-separated list from "audio", "text" (e.g., "audio,text" or "text")
OPENAI_TTS_MODEL="tts-1" # OpenAI TTS model (e.g., tts-1, tts-1-hd) - Used if Realtime API doesn't handle TTS or for separate TTS calls.
OPENAI_TTS_VOICE="alloy" # OpenAI TTS voice (e.g., alloy, echo, fable, onyx, nova, shimmer) - Used for TTS.
OPENAI_LANGUAGE="en" # Language code for STT (e.g., en, es). For Realtime API, language support is often model-specific.
OPENAI_INPUT_AUDIO_FORMAT="g711_ulaw" # Format of input audio sent to OpenAI. For direct u-law (8kHz) passthrough from Asterisk, set to "g711_ulaw" or the exact equivalent string OpenAI expects. VERIFY WITH OPENAI DOCS.
OPENAI_INPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for STT input. Note: For Realtime API with formats like "g711_ulaw", the sample rate (8000) is often implied by the format string. This variable might be used for other internal logic if any, but the format string sent to OpenAI is primary.
OPENAI_OUTPUT_AUDIO_FORMAT="g711_ulaw" # Desired TTS audio output format from OpenAI. For direct u-law (8kHz) playback in Asterisk, "g711_ulaw" or equivalent is recommended. VERIFY WITH OPENAI DOCS.
OPENAI_OUTPUT_AUDIO_SAMPLE_RATE="8000" # Sample rate for TTS output. Note: For Realtime API with formats like "g711_ulaw", the sample rate (8000) is often implied by the format string.

# Asterisk ARI Configuration (examples from ari-client.ts defaults)
ASTERISK_ARI_URL="http://localhost:8088"
ASTERISK_ARI_USERNAME="asterisk"
ASTERISK_ARI_PASSWORD="asterisk"
ASTERISK_ARI_APP_NAME="openai-ari-app" # Should match the Stasis app name in Asterisk dialplan
# ASTERISK_INBOUND_CONTEXT: Dialplan context where inbound calls are routed to the ARI application.
ASTERISK_INBOUND_CONTEXT="from-external" # Example context
# ASTERISK_DIAL_EXTENSION: The extension number within ASTERISK_INBOUND_CONTEXT that invokes the ARI app.
ASTERISK_DIAL_EXTENSION="1234" # Example extension

# RTP Host IP (IP address of this server where Asterisk should send RTP media)
RTP_HOST_IP="127.0.0.1" # Use actual host IP if Asterisk is on a different machine or in Docker
# RTP_MIN_PORT: Minimum port for RTP listeners. Default: 10000
RTP_MIN_PORT=10000
# RTP_MAX_PORT: Maximum port for RTP listeners. Default: 10010
RTP_MAX_PORT=10010

# Server Configuration
PORT="8081" # Port for the WebSocket server to listen on
# PUBLIC_URL: The publicly accessible URL for this websocket-server.
PUBLIC_URL="http://localhost:8081"
WEBSOCKET_SERVER_HOST_IP="0.0.0.0" # Host IP for the WebSocket server

# Logging Configuration
LOG_LEVEL="info" # Log level for the application (e.g., "error", "warn", "info", "debug", "silly"). Set to "debug" for verbose OpenAI API message logging.

# Application Behavior Configuration
# RECOGNITION_ACTIVATION_MODE: How recognition is activated. "VAD" or "MANUAL", "IMMEDIATE", "FIXED_DELAY". Default: VAD
RECOGNITION_ACTIVATION_MODE="VAD"

# VAD (Voice Activity Detection) Configuration
# VAD_SILENCE_THRESHOLD_MS: Duration of silence (in ms) after which speech is considered ended (if VAD active). Default: 250
VAD_SILENCE_THRESHOLD_MS=250
# VAD_RECOGNITION_ACTIVATION_MS: Duration of speech (in ms) to activate recognition (if VAD active). Default: 40
VAD_RECOGNITION_ACTIVATION_MS=40

# Speech Recognition Timers (seconds)
# NO_SPEECH_BEGIN_TIMEOUT_SECONDS: Timeout if no speech is detected at the beginning of interaction. Default: 3
NO_SPEECH_BEGIN_TIMEOUT_SECONDS=3
# SPEECH_COMPLETE_TIMEOUT_SECONDS: Timeout after speech is detected, waiting for completion. Default: 5
SPEECH_COMPLETE_TIMEOUT_SECONDS=5
# INITIAL_OPENAI_STREAM_IDLE_TIMEOUT_SECONDS: (Optional) Timeout in seconds for the initial OpenAI stream to become responsive. Default: 10
INITIAL_OPENAI_STREAM_IDLE_TIMEOUT_SECONDS=10

# DTMF Configuration
# DTMF_ENABLED: Enable or disable DTMF recognition. true or false. Default: true
DTMF_ENABLED="true"
# DTMF_INTERDIGIT_TIMEOUT_SECONDS: Timeout between DTMF digits. Default: 2
DTMF_INTERDIGIT_TIMEOUT_SECONDS=2
# DTMF_MAX_DIGITS: Maximum number of DTMF digits to collect. Default: 16
DTMF_MAX_DIGITS=16
# DTMF_TERMINATOR_DIGIT: DTMF digit that terminates input. Default: #
DTMF_TERMINATOR_DIGIT="#"

# Barge-In Configuration
# BARGE_IN_MODE_ENABLED: Allow user to interrupt playback. true or false. Default: true
BARGE_IN_MODE_ENABLED="true"
# BARGE_IN_DELAY_SECONDS: Delay before barge-in is active after playback starts. Default: 0.5
BARGE_IN_DELAY_SECONDS=0.5

# Configuration File Path
# CONFIG_FILE_PATH: Path to the JSON configuration file. Default: "config/default.json"
CONFIG_FILE_PATH="config/default.json"

# Greeting Audio Path (Example - used by ari-client.ts)
# GREETING_AUDIO_PATH="sound:your-custom-greeting" # Path to greeting audio file recognizable by Asterisk
