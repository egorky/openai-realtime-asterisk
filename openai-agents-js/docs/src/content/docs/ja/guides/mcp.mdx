---
title: MCP 連携
description: Learn how to utilize MCP servers as tools
---

import { Code } from '@astrojs/starlight/components';
import hostedAgentExample from '../../../../../../examples/docs/mcp/hostedAgent.ts?raw';
import hostedExample from '../../../../../../examples/docs/mcp/hosted.ts?raw';
import hostedStreamExample from '../../../../../../examples/docs/mcp/hostedStream.ts?raw';
import hostedHITLExample from '../../../../../../examples/docs/mcp/hostedHITL.ts?raw';
import streamableHttpExample from '../../../../../../examples/docs/mcp/streamableHttp.ts?raw';
import stdioExample from '../../../../../../examples/docs/mcp/stdio.ts?raw';

[ **Model Context Protocol (MCP)** ](https://modelcontextprotocol.io) は、アプリケーションが LLM にツールやコンテキストを提供する方法を標準化するオープンプロトコルです。MCP のドキュメントから引用します。

> MCP は、アプリケーションが LLM にコンテキストを提供する方法を標準化するオープンプロトコルです。MCP を AI アプリケーション向けの USB-C ポートと考えてください。USB-C が各種デバイスを周辺機器やアクセサリーに接続する標準化された方法を提供するのと同様に、MCP は AI モデルをさまざまなデータソースやツールに接続する標準化された方法を提供します。

この SDK がサポートする MCP サーバーは 3 種類あります。

1. **リモート MCP サーバーツール** – [OpenAI Responses API](https://platform.openai.com/docs/guides/tools-remote-mcp) によってツールとして使用されるリモート MCP サーバー
2. **Streamable HTTP MCP サーバー** – [Streamable HTTP トランスポート](https://modelcontextprotocol.io/docs/concepts/transports#streamable-http) を実装したローカルまたはリモートサーバー
3. **Stdio MCP サーバー** – 標準入出力経由でアクセスするサーバー（最もシンプルなオプション）

ユースケースに応じてサーバータイプを選択してください。

| 必要な内容                                                                           | 推奨オプション                     |
| ------------------------------------------------------------------------------------ | ---------------------------------- |
| OpenAI Responses のデフォルトモデルで、公開アクセス可能なリモートサーバーを呼び出す  | **1. リモート MCP サーバーツール** |
| 公開アクセス可能なリモートサーバーを利用しつつ、ツール呼び出しをローカルで実行したい | **2. Streamable HTTP**             |
| ローカルで実行している Streamable HTTP サーバーを使用する                            | **2. Streamable HTTP**             |
| OpenAI Responses 以外のモデルで、任意の Streamable HTTP サーバーを使用する           | **2. Streamable HTTP**             |
| 標準入出力プロトコルのみをサポートするローカル MCP サーバーと連携する                | **3. Stdio**                       |

## 1. リモート MCP サーバーツール

リモートツールでは、往復処理全体をモデル内部で完結させます。あなたのコードが MCP サーバーを呼び出す代わりに、OpenAI Responses API がリモートツールのエンドポイントを呼び出し、その結果をストリーミングでモデルへ返します。

以下はリモート MCP サーバーツールを使用する最小限の例です。リモート MCP サーバーの `label` と `url` を `hostedMcpTool` ユーティリティ関数に渡します。

<Code lang="typescript" code={hostedAgentExample} title="hostedAgent.ts" />

その後、`run` 関数（または独自の `Runner` インスタンスの `run` メソッド）でエージェントを実行できます。

<Code
  lang="typescript"
  code={hostedExample}
  title="Run with hosted MCP tools"
/>

インクリメンタルな MCP 実行結果をストリームする場合は、`Agent` を実行するときに `stream: true` を渡してください。

<Code
  lang="typescript"
  code={hostedStreamExample}
  title="Run with hosted MCP tools (streaming)"
/>

#### 任意の承認フロー

機微な操作の場合、個別のツール呼び出しに対して人による承認を必須にできます。`requireApproval: 'always'` もしくは、ツール名を `'never'` / `'always'` でマッピングした詳細オブジェクトを渡してください。

ツール呼び出しが安全かどうかをプログラムで判断できる場合は、[`onApproval` コールバック](https://github.com/openai/openai-agents-js/blob/main/examples/mcp/hosted-mcp-on-approval.ts) を使用して承認または拒否を行えます。人による承認が必要な場合は、ローカル関数ツールと同様に `interruptions` を使った [人間の介入（HITL）のアプローチ](/openai-agents-js/ja/guides/human-in-the-loop/) を利用できます。

<Code
  lang="typescript"
  code={hostedHITLExample}
  title="Human in the loop with hosted MCP tools"
/>

完全な動作例（リモートツール / Streamable HTTP / Stdio における Streaming、HITL、onApproval など）は GitHub リポジトリの [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) にあります。

## 2. Streamable HTTP MCP サーバー

エージェントがローカルまたはリモートの Streamable HTTP MCP サーバーと直接通信する場合、`MCPServerStreamableHttp` をサーバーの `url`、`name`、および任意の設定とともにインスタンス化します。

<Code
  lang="typescript"
  code={streamableHttpExample}
  title="Run with Streamable HTTP MCP servers"
/>

コンストラクタでは、`authProvider`、`requestInit`、`reconnectionOptions`、`sessionId` などの MCP TypeScript-SDK 追加オプションも指定できます。詳細は [MCP TypeScript SDK のリポジトリ](https://github.com/modelcontextprotocol/typescript-sdk) とドキュメントを参照してください。

## 3. Stdio MCP サーバー

標準入出力のみを公開するサーバーの場合、`fullCommand` を指定して `MCPServerStdio` をインスタンス化します。

<Code
  lang="typescript"
  code={stdioExample}
  title="Run with Stdio MCP servers"
/>

## その他の注意点

**Streamable HTTP** と **Stdio** サーバーでは、`Agent` が実行されるたびに `list_tools()` を呼び出して利用可能なツールを取得します。この往復処理は、とくにリモートサーバーでは遅延を招く可能性があるため、`MCPServerStdio` または `MCPServerStreamableHttp` に `cacheToolsList: true` を渡して結果をメモリにキャッシュできます。

ツール一覧が変わらないと確信できる場合のみ有効にしてください。後でキャッシュを無効化するには、サーバーインスタンスの `invalidateToolsCache()` を呼び出します。

## 参考情報

- [Model Context Protocol](https://modelcontextprotocol.io/) – 公式仕様
- [examples/mcp](https://github.com/openai/openai-agents-js/tree/main/examples/mcp) – 上記で参照した実行可能デモ
